{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. load json file to database\n",
    "this jupyter notebook is able to load json files into sqlite3 database core.db with twitter/user table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**input** : json files at folder /extract  \n",
    "**output**: database core.db at folder ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import sqlite3\n",
    "import os\n",
    "import time\n",
    "import re\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import pickle\n",
    "\n",
    "# create db file and conn\n",
    "db_file = open('core.db','w+')\n",
    "conn = sqlite3.connect('core.db',isolation_level = None)\n",
    "cur = conn.cursor()\n",
    "\n",
    "# change working dir\n",
    "os.chdir('./extract')\n",
    "\n",
    "# get json file name list\n",
    "file_list = []\n",
    "for file in os.listdir():\n",
    "    if os.path.splitext(file)[1][1:] == \"json\":\n",
    "        file_list.append(file)\n",
    "print('amount of json file : ', len(file_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get score using analyzer.polarity_scores\n",
    "\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "def get_score(sentence):\n",
    "    vs = analyzer.polarity_scores(sentence)\n",
    "    return vs['compound']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''create twitter table'''\n",
    "\n",
    "query = '''\n",
    "CREATE TABLE twitter(\n",
    "    'created_at' TEXT,\n",
    "    'id' INTEGER,\n",
    "    'text' TEXT,\n",
    "    'in_reply_to_status_id' INTEGER,\n",
    "    'in_reply_to_user_id' INTEGER,\n",
    "    'user_mention_id' TEXT,\n",
    "    'hashtags' TEXT,\n",
    "    'user_id' INTEGER,\n",
    "    'timestamp_ms' INT,\n",
    "    'sentiment_score' REAL,\n",
    "    PRIMARY KEY (id) ON CONFLICT IGNORE\n",
    ");'''\n",
    "\n",
    "cur.execute(query)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''create user table'''\n",
    "\n",
    "query = '''\n",
    "CREATE TABLE user(\n",
    "    'user_id' INTEGER,\n",
    "    'user_name' TEXT,\n",
    "    PRIMARY KEY (user_id) ON CONFLICT IGNORE\n",
    ");'''\n",
    "\n",
    "cur.execute(query)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract information from json file to query string\n",
    "def load_user_cursor(dict_0):\n",
    "    dict_user = {}\n",
    "    try:\n",
    "        dict_user['user_id'] = dict_0['user']['id']\n",
    "    except KeyError:\n",
    "        dict_user['user_id'] = '' \n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        dict_user['user_name'] = dict_0['user']['name']\n",
    "        #--------- smooth insert to sqlite3 ---------#\n",
    "        if type(dict_user['user_name']) == str:\n",
    "            if \"'\" in dict_user['user_name']: # replace single quotation mark\n",
    "                dict_user['user_name'] = dict_user['user_name'].replace(\"\\'\",\"\\\"\")\n",
    "        elif dict_user['user_name'] == None:\n",
    "            dict_user['user_name'] = ''\n",
    "        #--------------------------------------------#\n",
    "    except KeyError:\n",
    "        dict_user['user_name'] = '' \n",
    "        pass\n",
    "    \n",
    "    query = \"INSERT INTO user('user_id', 'user_name') VALUES ('{}','{}');\".format(dict_user['user_id'], dict_user['user_name'])\n",
    "\n",
    "    return query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract information from json file to query string\n",
    "def load_tweet_cursor(dict_0):\n",
    "    '''load one tweet into dict_tw and insert into database'''\n",
    "    \n",
    "    dict_tw = {}\n",
    "    key_list = ['created_at', 'id', 'text',\n",
    "                'in_reply_to_status_id',  'in_reply_to_user_id','timestamp_ms']\n",
    "    \n",
    "    # put keys into dict_tw, use try...except to aviod missing key\n",
    "    \n",
    "\n",
    "    # using loop making dictionary\n",
    "    for key in key_list:\n",
    "        try:\n",
    "            data_value = dict_0[key]\n",
    "            #--------- smooth insert to sqlite3 ---------#\n",
    "            if type(data_value) == str:\n",
    "                if \"'\" in data_value: # replace single quotation mark\n",
    "                    data_value = data_value.replace(\"\\'\",\"\\\"\")\n",
    "            elif data_value == None:\n",
    "                data_value = ''\n",
    "            #--------------------------------------------#\n",
    "            dict_tw[key] = data_value\n",
    "        except KeyError:\n",
    "            dict_tw[key] = ''\n",
    "            pass\n",
    "    \n",
    "    # put user id into dict_tw, use try...except to aviod missing key\n",
    "    try:\n",
    "        dict_tw['user_id'] = dict_0['user']['id']\n",
    "    except KeyError:\n",
    "        dict_tw['user_id'] = '' \n",
    "        pass\n",
    "        \n",
    "    #------------------------------------hashtags_json------------------------------#\n",
    "    try:\n",
    "        hashtags_json = str(dict_0['entities']['hashtags'])\n",
    "        if hashtags_json != '[]':\n",
    "            hashtags_str = str(re.findall(\"'text': '(.*?)'\", hashtags_json))\n",
    "            hashtags_str = hashtags_str.replace('\\'','\\\"')\n",
    "        else:\n",
    "            hashtags_str = ''\n",
    "    except Exception:\n",
    "        hashtags_str = ''\n",
    "    #----------------------------------------------------------------------------------#\n",
    "    \n",
    "    #-----------------------------------user_mention_json------------------------------#\n",
    "    try:\n",
    "        user_mention_json = str(dict_0['entities']['user_mentions'])\n",
    "        if user_mention_json != '[]':\n",
    "            user_mention_str = str(re.findall(\"'id': (\\w*)\", user_mention_json_dict))\n",
    "            user_mention_str = user_mention_str.replace('\\'','\\\"')\n",
    "        else:\n",
    "            user_mention_str = ''\n",
    "    except Exception:\n",
    "        user_mention_str = ''\n",
    "    #----------------------------------------------------------------------------------#\n",
    "    \n",
    "    #-----------------------------------sentiment score--------------------------------#\n",
    "    try:\n",
    "        sentiment_score = get_score(dict_tw['text'])\n",
    "    except Exception:\n",
    "        sentiment_score = ''\n",
    "    #----------------------------------------------------------------------------------#\n",
    "    \n",
    "    query = \"INSERT INTO twitter('created_at', 'id',  'text', 'in_reply_to_status_id', 'in_reply_to_user_id', 'user_mention_id','hashtags','user_id','timestamp_ms','sentiment_score') VALUES ('{}','{}','{}','{}','{}','{}','{}','{}','{}','{}');\".format(dict_tw['created_at'], dict_tw['id'], dict_tw['text'],dict_tw['in_reply_to_status_id'],dict_tw['in_reply_to_user_id'],user_mention_str,hashtags_str,dict_tw['user_id'],dict_tw['timestamp_ms'],sentiment_score)\n",
    "    \n",
    "    return query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert json to dictionary\n",
    "def ReadJson(json_file):\n",
    "    data = []\n",
    "    error_list = []\n",
    "    line_counter = 0\n",
    "    with open(json_file) as f:\n",
    "        for line in f:\n",
    "            try:\n",
    "                data.append(json.loads(line))\n",
    "                line_counter += 1\n",
    "            except ValueError:\n",
    "                error_list.append(line_counter)\n",
    "                line_counter += 1\n",
    "                pass\n",
    "\n",
    "    if len(error_list) != 0:\n",
    "        print('ReadJson {} has {} errors. Errors in line {}.'.format(json_file,len(error_list),error_list))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "'''execute loading : only english'''\n",
    "print('amount of json file : ', len(file_list))\n",
    "\n",
    "total_time_start = time.time()                                                              # total time counter start\n",
    "'''open file (will be replaced by json loop)'''\n",
    "\n",
    "counter = 0\n",
    "\n",
    "for json_file_name in file_list:\n",
    "    tweet_query_lst = []                                                                    # lists for insertion, contains all tweets query in this json file\n",
    "    user_query_lst = []\n",
    "    '''time counter starts'''\n",
    "    starttime = time.time()                                                                 # json file time start\n",
    "    \n",
    "    #-----------------------------READ JSON TO LIST----------------------------------#\n",
    "    '''for loop, loop though the tweets inside one json file'''\n",
    "    tweets_list = ReadJson(json_file_name)                                                  # convert json into dictionary\n",
    "\n",
    "    for tweet in tweets_list:\n",
    "        try:\n",
    "            if tweet['lang'] == 'en':                                                       # filter: only select english tweets\n",
    "                tweet_query_lst.append(load_tweet_cursor(tweet))\n",
    "                user_query_lst.append(load_user_cursor(tweet))\n",
    "            else:\n",
    "                pass\n",
    "        except KeyError:\n",
    "            pass\n",
    "    #-----------------------------END JSON READER-----------------------------------#\n",
    "    \n",
    "    #-----------------------------START INSERT--------------------------------------#\n",
    "    tweet_all = tweet_query_lst+user_query_lst\n",
    "    \n",
    "    db_start = time.time()\n",
    "    conn.execute(\"BEGIN TRANSACTION\")\n",
    "    for query in tweet_all:\n",
    "        try:\n",
    "            conn.execute(query)\n",
    "        except ValueError:\n",
    "            print('Insert error :',query)\n",
    "            pass\n",
    "    conn.execute(\"COMMIT\")\n",
    "    db_end = time.time()\n",
    "    #----------------------------END INSERT----------------------------------------#\n",
    "    \n",
    "    '''time counter ends'''\n",
    "    endtime = time.time()                                                                     # end json file time, meaning this json file is done and can be close\n",
    "#     print ('database in ' + str(round((db_end - db_start),2)) +' sec.')                     # insert time print\n",
    "    \n",
    "    '''print out load time'''\n",
    "    print ('load '+ json_file_name + ' in ' + str(round((endtime - starttime),2)) +' sec.')   # json file time print\n",
    "    print(counter+1,'/',len(file_list))                                                       # print load progress\n",
    "    counter += 1\n",
    "\n",
    "\n",
    "total_time_end = time.time()\n",
    "print('total time ' + str(round((total_time_end - total_time_start)/60,2)) +' mins.')         # total time print\n",
    "print('Done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
