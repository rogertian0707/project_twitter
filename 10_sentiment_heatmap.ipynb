{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. sentiment heatmap\n",
    "Plot heatmap of user sentiment after n number of interactions and statistical test for every number of interactions\n",
    "\n",
    "**input**  :pickle file at /obj folder  \n",
    "**output** :plot of sentiment heatmap, statistical test result\n",
    "\n",
    "**note that this jupyter notebook contains alternative solution if too few of conversations are found in given zips**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as st\n",
    "from matplotlib.colors import LinearSegmentedColormap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airlines = {56377143: 'KLM', 106062176: 'Air France', 18332190: 'British Airways', 22536055: 'American Airlines', \n",
    "            124476322: 'Lufthansa', 26223583: 'Air Berlin', 2182373406: 'Air Berlin Assist', 38676903: 'easyJet', \n",
    "            1542862735: 'Ryanair', 253340062: 'Singapore Airlines', 218730857: 'Qantas',\n",
    "            45621423: 'Etihad Airways', 20626359: 'Virgin Atlantic'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extracts the conversations list from a pickle file in the obj folder\n",
    "conversations = pickle.load(open(\"obj/conversations_with_scores.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def CountAirline(airline, conversations):\n",
    "    '''in: airline_id (integer), conversations (list)\n",
    "      out: count of appearances (integer)\n",
    "      \n",
    "    This function counts how many times an airline appears in the conversations list.\n",
    "    '''\n",
    "    count = 0\n",
    "\n",
    "    for conversation in conversations:\n",
    "        for tweet in conversation:\n",
    "            if tweet[1] == airline:\n",
    "                count +=1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# In this cell we check the maximum number of appearances of which airline in the conversations list and AA's count\n",
    "max_count, airline_max = 0, 0\n",
    "aa_count = CountAirline(22536055, conversations)\n",
    "\n",
    "for air_id, air_name in airlines.items():\n",
    "    count = CountAirline(air_id, conversations)\n",
    "    if count > max_count:\n",
    "        max_count = count\n",
    "        airline_max = air_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this cell we give you an alternative if AA's count is 0, or significantly lower than the others'.\n",
    "# That is because we can not do the visuals if AA's count is 0.\n",
    "if aa_count == 0:\n",
    "    print(\"American Airlines does not appear in any of the conversations in the given Json files, so the code and \"\\\n",
    "          \"visualizations below will not work. Therefore, we use another airline to do the visualizations. \"\\\n",
    "          \"The airline that appears most in the given Json files is {}, with {} appearances.\".format(airlines[airline_max],\n",
    "                                                                                                     max_count))\n",
    "    airline_to_be_analyzed = airline_max\n",
    "\n",
    "elif airline_max == 22536055:\n",
    "    print(\"American Airlines has the most appearances in the conversations from the Json files, so it will \"\\\n",
    "          \"be analyzed below.\")\n",
    "    airline_to_be_analyzed = 22536055\n",
    "    \n",
    "else:\n",
    "    analyze_AA = input(\"American Airlines has {} appearances. The airline with most appearances ({}) is {}. It might \"\\\n",
    "                       \"be more interesting to analyze the second airline because it may have way more appearances. \"\\\n",
    "                       \"Do you still want to analyze American Airlines? Type Y and hit enter for 'yes' or type N and hit \"\\\n",
    "                       \"enter for 'no': \"\\\n",
    "                       .format(aa_count, max_count, airlines[airline_max]))\n",
    "    if analyze_AA in 'yesYesÝý':\n",
    "        airline_to_be_analyzed = 22536055\n",
    "    else:\n",
    "        airline_to_be_analyzed = airline_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def MakeHeatmap(conversations, airline):\n",
    "    '''in: a list of completed filtered conversations with sentiment scores, user_id of an airline (integer)\n",
    "      out: three dataframes, of which the first is used for plotting the heatmap and the other two for statistics\n",
    "      \n",
    "    This function turns a list of completed filtered conversations with sentiment scores into three dataframes:\n",
    "    one that can be used to plot a heatmap and the other two to calculate statistics and do hypotheses.\n",
    "    \n",
    "    The heatmap represents the influence airlines interacting with customers have on the customers' sentiment.\n",
    "    '''\n",
    "    categories = np.array([1,2,3,4,5])\n",
    "    \n",
    "    cutoff = 6\n",
    "    responses = np.arange(0, cutoff+1)\n",
    "    \n",
    "    score_dataframe = pd.DataFrame(index = categories, columns = responses)\n",
    "    second_dataframe = pd.DataFrame(index = categories, columns = responses)\n",
    "\n",
    "    for conversation in conversations:\n",
    "        conversation = conversation[::-1]\n",
    "        \n",
    "        # Put the first tweet in one of the five categories\n",
    "        category = (conversation[0][4] < -0.6) + (conversation[0][4] < -0.2) + (conversation[0][4] < 0.2) + (conversation[0][4] < 0.6) + 1\n",
    "        begin_score = np.around(conversation[0][4], 1)\n",
    "\n",
    "        airline_count = 0\n",
    "        airline_found = False\n",
    "\n",
    "        # This forloop adds either a score or 1 to data in the DataFrames\n",
    "        for tweet in conversation:\n",
    "            # If an airline responds\n",
    "            if tweet[1] == airline:\n",
    "                if not airline_found:\n",
    "                    if format(score_dataframe.loc[category, 0]) == 'nan':\n",
    "                        score_dataframe.loc[category, 0] = [begin_score, 1]\n",
    "                        second_dataframe.loc[category, 0] = [begin_score]\n",
    "                    else:\n",
    "                        score_dataframe.loc[category, 0][0] += begin_score\n",
    "                        score_dataframe.loc[category, 0][1] += 1\n",
    "                        second_dataframe.loc[category, 0].append(begin_score)\n",
    "                    airline_count += 1\n",
    "                    airline_found = True\n",
    "                    \n",
    "                elif airline_found:\n",
    "                    if airline_count < cutoff:\n",
    "                        airline_count += 1\n",
    "            \n",
    "            # If a person responds\n",
    "            elif tweet[1] != airline and airline_found:\n",
    "                score = tweet[4]\n",
    "                if format(score_dataframe.loc[category, airline_count]) == 'nan':\n",
    "                    score_dataframe.loc[category, airline_count] = [score, 1]\n",
    "                    second_dataframe.loc[category, airline_count] = [score]\n",
    "                else:\n",
    "                    score_dataframe.loc[category, airline_count][0] += score\n",
    "                    score_dataframe.loc[category, airline_count][1] += 1\n",
    "                    second_dataframe.loc[category, airline_count].append(score)\n",
    "                    \n",
    "    scores_with_weights = score_dataframe.copy()\n",
    "    second_dataframe_lists = second_dataframe.copy()\n",
    "    \n",
    "    # For each category, calculate some statistics\n",
    "    for category in categories:\n",
    "        for response in responses:\n",
    "            if format(score_dataframe.loc[category, response]) != 'nan':\n",
    "                score_dataframe.loc[category, response] = float(score_dataframe.loc[category, response][0]/score_dataframe.loc[category, response][1])\n",
    "                second_dataframe.loc[category, response] = np.array(second_dataframe.loc[category, response]).std()\n",
    "               \n",
    "    # Debugging a very nasty error\n",
    "    second_dataframe = second_dataframe.astype(np.float64)                \n",
    "    score_dataframe = score_dataframe.astype(np.float64)\n",
    "    \n",
    "    return score_dataframe, scores_with_weights, second_dataframe_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# In this cell we define the color gradient for the heatmap.\n",
    "cdict = {'red':   ((0.00, (254/255), (254/255)),\n",
    "                   (0.25, (254/255), (254/255)),\n",
    "                   (0.40, (254/255), (254/255)),\n",
    "                   (0.50, (254/255), (254/255)),\n",
    "                   (0.60, (154/255), (154/255)),\n",
    "                   (0.75, (154/255), (154/255)),\n",
    "                   (1.00, 0, 0)),\n",
    "\n",
    "         'green': ((0.00, 0, 0),\n",
    "                   (0.25, (165/255), (165/255)),\n",
    "                   (0.40, (165/255), (165/255)),\n",
    "                   (0.50, (215/255), (215/255)),\n",
    "                   (0.60, (205/255), (205/255)),\n",
    "                   (0.75, (205/255), (205/255)),\n",
    "                   (1.00, (128/255), (128/255))),\n",
    "\n",
    "         'blue':  ((0.00, 0, 0),\n",
    "                   (0.25, 0, 0),\n",
    "                   (0.40, 0, 0),\n",
    "                   (0.50, 0, 0),\n",
    "                   (0.60, (50/255), (50/255)),\n",
    "                   (0.75, (50/255), (50/255)),\n",
    "                   (1.00, (1/255), (1/255))),\n",
    "        }\n",
    "\n",
    "test_cmap = LinearSegmentedColormap('Test', cdict)\n",
    "plt.register_cmap(cmap=test_cmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def PlotHeatmap(score_dataframe, airline):\n",
    "    '''in: a dataframe which is very plottable as a heatmap, user_id of an airline (integer)\n",
    "    \n",
    "    Plots the heatmap.\n",
    "    '''\n",
    "    airline_name = airlines[airline]\n",
    "    plt.figure(figsize=(12,8))\n",
    "    \n",
    "    with sns.axes_style(\"white\"):\n",
    "        sns.heatmap(score_dataframe, cmap='Test', mask=score_dataframe.isnull(),\n",
    "                    cbar_kws={\"ticks\":[-0.73, -0.45, -0.2, 0, 0.2, 0.45, 0.74]}, vmin=-0.731065, vmax=0.740667)\n",
    "        \n",
    "        plt.yticks(rotation=0)\n",
    "        plt.suptitle('Tweet sentiment by airline and influence of {} on sentiment of customers'.format(airline_name), size=20)\n",
    "        plt.title('Each cell represents the average final sentiment', size=15)\n",
    "        plt.xlabel('Average sentiment after n number of interactions by {}'.format(airline_name), size=15)\n",
    "        plt.ylabel('Sentiment score of the first tweet in the conversation', size=15)\n",
    "        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score_dataframe, scores_with_weights, second_dataframe_lists = MakeHeatmap(conversations, airline_to_be_analyzed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PlotHeatmap(score_dataframe, airline_to_be_analyzed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell calculates the standard deviation (of the sentiment after the interaction) for\n",
    "# every number of interactions\n",
    "standard_deviations = []\n",
    "total_lists = {}\n",
    "\n",
    "for column_number in list(second_dataframe_lists):\n",
    "    total_list = []\n",
    "    \n",
    "    for partial_list in second_dataframe_lists[:][column_number]:\n",
    "        if format(partial_list) != 'nan':\n",
    "            total_list += partial_list\n",
    "        \n",
    "    total_lists[column_number] = total_list\n",
    "        \n",
    "    standard_deviations.append(np.array(total_list).std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell collects some statistics for every number of interactions an airline did in the following order:\n",
    "# interactions, observations, average (of the sentiment after the interaction), \n",
    "# standard deviation (of the sentiment after the interaction)\n",
    "statistics = []\n",
    "\n",
    "for i in range(7):\n",
    "    try:\n",
    "        stats = [i]\n",
    "        score_count = [0, 0]\n",
    "\n",
    "        for score in scores_with_weights.loc[:, i]:\n",
    "            if type(score) == list:\n",
    "                score_count[0] += score[0]\n",
    "                score_count[1] += score[1]\n",
    "\n",
    "        stats.append(score_count[1])\n",
    "        stats.append(score_count[0]/score_count[1])\n",
    "        stats.append(standard_deviations[i])\n",
    "\n",
    "        statistics.append(stats)\n",
    "        print('{:>2} interactions: {:>5} instances, average = {:>7.4f}, standard deviation = {:.3f}'.format(stats[0], stats[1],\n",
    "                                                                                                            stats[2], stats[3]))\n",
    "    except:\n",
    "        print('No data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ttest(x, y):\n",
    "    '''in: x and y (integers), where x and y are the amount of interactions you want to compare (and x > y)\n",
    "      out: the outcome of the t-test\n",
    "    '''\n",
    "    try:\n",
    "        data_x = statistics[x]\n",
    "        data_y = statistics[y]\n",
    "        \n",
    "        t = (data_x[2]-data_y[2])/((data_x[3]**2/data_x[1])+(data_y[3]**2/data_y[1]))**0.5\n",
    "        df = ((data_x[3]**2/data_x[1])+(data_y[3]**2/data_y[1]))**2/(((data_x[3]**2/data_x[1])**2/(data_x[1]-1))+((data_y[3]**2/data_y[1])**2/(data_y[1]-1)))\n",
    "        p = 1-st.t.cdf(t, df, loc=0, scale=1)\n",
    "        if p<0.05:\n",
    "            rejected = 'rejected'\n",
    "        else:\n",
    "            rejected = 'not rejected'\n",
    "        print('H0: mu{0} = mu{1}\\tHa: mu{0} > mu{1}\\nt = {2:>6.3f}, p = {3:.4f}, so H0 is {4}\\n'.format(data_x[0], data_y[0],\n",
    "                                                                                                        t, p, rejected))\n",
    "    except:\n",
    "        print('No or too little data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Various t-tests\n",
    "ttest(1, 0)\n",
    "ttest(2, 0)\n",
    "ttest(2, 1)\n",
    "ttest(3, 0)\n",
    "ttest(3, 2)\n",
    "ttest(4, 2)\n",
    "ttest(4, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
